{"cells":[{"cell_type":"markdown","metadata":{},"source":["The bank marketing dataset was first presented in Moro, S., Laureano, R. and Cortex, P. (2011). The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. In the original paper, the dataset was used for a classification problem -- predicting whether or not a client has subscribed to a term deposit based on features including bank client data, data about the marketing campaigns, and some socioeconomic data. Here, we use only the bank client data to try and cluster bank clients into different groups. Such analysis may be important to banking institutions in designing marketing campaigns, as an understanding of different client groups may help banks to develop different marketing campaigns target towards each group of clients, which may potentially be be more effective than a universal marketing campaign for all clients.\n","\n","**Description of the variables in the dataset:**\n","\n","*Bank client data:*\n","\n","1. age (numeric)\n","2. job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n","3. marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n","4. education (categorical: 'primary', 'secondary', 'tertiary', 'unknown')\n","5. default: has credit in default? (categorical: 'no','yes','unknown')\n","6. housing: has housing loan? (categorical: 'no','yes','unknown')\n","6. balance: bank balance\n","7. loan: has personal loan? (categorical: 'no','yes','unknown')\n","\n","*Related with the last contact of the current campaign:*\n","\n","9. contact: contact communication type (categorical: 'cellular','telephone')\n","9. month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n","10. day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n","11. duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n","\n","*Other attributes:*\n","\n","13. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n","13. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n","14. previous: number of contacts performed before this campaign and for this client (numeric)\n","15. poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n","\n","*Social and economic context attributes:*\n","\n","17. emp.var.rate: employment variation rate - quarterly indicator (numeric)\n","17. cons.price.idx: consumer price index - monthly indicator (numeric)\n","18. cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n","19. euribor3m: euribor 3 month rate - daily indicator (numeric)\n","20. nr.employed: number of employees - quarterly indicator (numeric)\n","\n","*Output variable (desired target):*\n","\n","22. y - has the client subscribed a term deposit? (binary: 'yes','no')\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:08:30.899454Z","iopub.status.busy":"2023-04-18T18:08:30.898688Z","iopub.status.idle":"2023-04-18T18:08:32.981663Z","shell.execute_reply":"2023-04-18T18:08:32.980089Z","shell.execute_reply.started":"2023-04-18T18:08:30.899394Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'kmodes'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler, StandardScaler\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkmodes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkmodes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KModes\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhierarchy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m linkage, cut_tree, dendrogram\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'kmodes'"]}],"source":["from matplotlib import pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","import numpy as np\n","from sklearn.cluster import KMeans\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from kmodes.kmodes import KModes\n","from scipy.cluster.hierarchy import linkage, cut_tree, dendrogram\n","from sklearn.decomposition import PCA\n","import warnings\n","warnings.filterwarnings('ignore')\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{},"source":["# Importing and cleaning data"]},{"cell_type":"markdown","metadata":{},"source":["The dataset we use is contained in the file bank-additional.csv, which is itself available in the zip file bank-additional.zip, which is available on the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip). Importing the dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:08:32.984023Z","iopub.status.busy":"2023-04-18T18:08:32.983661Z","iopub.status.idle":"2023-04-18T18:08:33.103645Z","shell.execute_reply":"2023-04-18T18:08:33.101512Z","shell.execute_reply.started":"2023-04-18T18:08:32.983988Z"},"trusted":true},"outputs":[],"source":["data = pd.read_csv('/kaggle/input/bank-marketing-dataset/bank.csv')\n","data.head()"]},{"cell_type":"markdown","metadata":{},"source":["We keep only the variables related to bank client data:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:08:33.107508Z","iopub.status.busy":"2023-04-18T18:08:33.105616Z","iopub.status.idle":"2023-04-18T18:08:33.135425Z","shell.execute_reply":"2023-04-18T18:08:33.133554Z","shell.execute_reply.started":"2023-04-18T18:08:33.107444Z"},"trusted":true},"outputs":[],"source":["data = data.iloc[:, :8]\n","data.head()"]},{"cell_type":"markdown","metadata":{},"source":["Checking the number of rows and columns in the dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:08:33.141341Z","iopub.status.busy":"2023-04-18T18:08:33.139667Z","iopub.status.idle":"2023-04-18T18:08:33.148795Z","shell.execute_reply":"2023-04-18T18:08:33.1473Z","shell.execute_reply.started":"2023-04-18T18:08:33.14128Z"},"trusted":true},"outputs":[],"source":["print(f'There are {data.shape[0]} rows and {data.shape[1]} columns.')"]},{"cell_type":"markdown","metadata":{},"source":["Checking if there are any duplicate rows:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:08:33.151839Z","iopub.status.busy":"2023-04-18T18:08:33.150567Z","iopub.status.idle":"2023-04-18T18:08:33.186531Z","shell.execute_reply":"2023-04-18T18:08:33.184911Z","shell.execute_reply.started":"2023-04-18T18:08:33.15173Z"},"trusted":true},"outputs":[],"source":["data.duplicated().sum()"]},{"cell_type":"markdown","metadata":{},"source":["There are 846 duplicated rows -- which is not a lot considering the number of rows in the dataset. We therefore remove the duplicate rows."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:08:33.189065Z","iopub.status.busy":"2023-04-18T18:08:33.188333Z","iopub.status.idle":"2023-04-18T18:08:33.211335Z","shell.execute_reply":"2023-04-18T18:08:33.209843Z","shell.execute_reply.started":"2023-04-18T18:08:33.189012Z"},"trusted":true},"outputs":[],"source":["data.drop_duplicates(inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["Checking for any missing values:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:08:33.214431Z","iopub.status.busy":"2023-04-18T18:08:33.213059Z","iopub.status.idle":"2023-04-18T18:08:33.234576Z","shell.execute_reply":"2023-04-18T18:08:33.232979Z","shell.execute_reply.started":"2023-04-18T18:08:33.214372Z"},"trusted":true},"outputs":[],"source":["data.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["Checking the data types of the features:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:08:33.237783Z","iopub.status.busy":"2023-04-18T18:08:33.236818Z","iopub.status.idle":"2023-04-18T18:08:33.249724Z","shell.execute_reply":"2023-04-18T18:08:33.247965Z","shell.execute_reply.started":"2023-04-18T18:08:33.237724Z"},"trusted":true},"outputs":[],"source":["data.dtypes"]},{"cell_type":"markdown","metadata":{},"source":["The dataset has one numeric variable, the age, and six categorical variables. Converting the data types of the categorical columns to the type 'category':"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:08:33.252829Z","iopub.status.busy":"2023-04-18T18:08:33.251916Z","iopub.status.idle":"2023-04-18T18:08:33.294417Z","shell.execute_reply":"2023-04-18T18:08:33.29297Z","shell.execute_reply.started":"2023-04-18T18:08:33.252776Z"},"trusted":true},"outputs":[],"source":["cat_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan']\n","\n","for col in cat_cols:\n","    data[col] = data[col].astype('category')\n","\n","data.dtypes"]},{"cell_type":"markdown","metadata":{},"source":["Finally, checking the unique values of the categorical columns to see if they match the description of the dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:08:33.301169Z","iopub.status.busy":"2023-04-18T18:08:33.300632Z","iopub.status.idle":"2023-04-18T18:08:33.325679Z","shell.execute_reply":"2023-04-18T18:08:33.324227Z","shell.execute_reply.started":"2023-04-18T18:08:33.301118Z"},"trusted":true},"outputs":[],"source":["for col in cat_cols:\n","    print(f'{col}:')\n","    print(data[col].unique())\n","    print('\\n')"]},{"cell_type":"markdown","metadata":{},"source":["All categorical values match the dataset description. We now proceed to an exploratory analysis of the data."]},{"cell_type":"markdown","metadata":{},"source":["# EDA"]},{"cell_type":"markdown","metadata":{},"source":["We begin by producing frequency plots for the categorical variables:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:08:33.329668Z","iopub.status.busy":"2023-04-18T18:08:33.327832Z","iopub.status.idle":"2023-04-18T18:08:34.703038Z","shell.execute_reply":"2023-04-18T18:08:34.702008Z","shell.execute_reply.started":"2023-04-18T18:08:33.329604Z"},"trusted":true},"outputs":[],"source":["sns.set_style('white')\n","\n","fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(20, 10))\n","fig.subplots_adjust(hspace=0.7)\n","\n","sns.histplot(x = data['job'], multiple=\"dodge\", stat='density', shrink=0.8, common_norm=False, ax=axs[0,0])\n","axs[0,0].set_xticklabels(list(data['job'].unique()), rotation = 90)\n","sns.histplot(x = data['marital'], multiple=\"dodge\", stat='density', shrink=0.8, common_norm=False, ax=axs[0,1])\n","axs[0,1].set_xticklabels(list(data['marital'].unique()), rotation = 90)\n","sns.histplot(x = data['education'], multiple=\"dodge\", stat='density', shrink=0.8, common_norm=False, ax=axs[0,2])\n","axs[0,2].set_xticklabels(list(data['education'].unique()), rotation = 90)\n","sns.histplot(x = data['default'], multiple=\"dodge\", stat='density', shrink=0.8, common_norm=False, ax=axs[1,0])\n","axs[1,0].set_xticklabels(list(data['default'].unique()), rotation = 90)\n","sns.histplot(x = data['housing'], multiple=\"dodge\", stat='density', shrink=0.8, common_norm=False, ax=axs[1,1])\n","axs[1,1].set_xticklabels(list(data['housing'].unique()), rotation = 90)\n","sns.histplot(x = data['loan'], multiple=\"dodge\", stat='density', shrink=0.8, common_norm=False, ax=axs[1,2])\n","axs[1,2].set_xticklabels(list(data['loan'].unique()), rotation = 90)\n","\n","plt.suptitle('Frequency plots for the categorical variables')\n","\n","for ax in axs.ravel():\n","    ax.set_ylabel('')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["We see that most of the bank's clients are retired. Most of the clients are unmarried or divorced, have tertiary or primary education, have no credit in default or personal loans. The proportion of clients with and without housing loans is roughly similar."]},{"cell_type":"markdown","metadata":{},"source":["Visualizing the distribution of ages of the clients:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:08:34.704319Z","iopub.status.busy":"2023-04-18T18:08:34.704006Z","iopub.status.idle":"2023-04-18T18:08:35.023285Z","shell.execute_reply":"2023-04-18T18:08:35.021972Z","shell.execute_reply.started":"2023-04-18T18:08:34.704287Z"},"trusted":true},"outputs":[],"source":["sns.histplot(data=data, x='age', bins=[10, 20, 30, 40, 50, 60, 70, 80, 90])\n","plt.title(\"Distribution of ages of the bank's clients\")\n","plt.xticks([10, 20, 30, 40, 50, 60, 70, 80, 90])\n","plt.ylabel('Count')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Most of the bank's clients are between 30 to 40 years of age."]},{"cell_type":"markdown","metadata":{},"source":["Visualizing the distribution of bank balances:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:08:35.02585Z","iopub.status.busy":"2023-04-18T18:08:35.024848Z","iopub.status.idle":"2023-04-18T18:08:36.44834Z","shell.execute_reply":"2023-04-18T18:08:36.447346Z","shell.execute_reply.started":"2023-04-18T18:08:35.025784Z"},"trusted":true},"outputs":[],"source":["sns.histplot(data=data, x='balance')\n","plt.title(\"Distribution of bank balances\")\n","plt.ylabel('Count')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["The bank balances are positively skewed, with most clients having less than 10,000 euros and some having a lot more."]},{"cell_type":"markdown","metadata":{},"source":["# Clustering"]},{"cell_type":"markdown","metadata":{},"source":["#### K-Means clustering"]},{"cell_type":"markdown","metadata":{},"source":["We begin by using K-Means clustering. The K-Means clustering algorithm works by initially randomly assigning K cluster centers in p dimensional space, where p is the number of features. Then, the distances from each observation to each cluster center are calculated, and the observation is assigned to its closest cluster. Usually, the Euclidean distance is taken as the metric. Then, the cluster centers are recomputed as the mean of the observations in each cluster. This process is repeated until the cluster assignments do not change in successive iterations. The final cluster assignment depends on the initial random assignment of cluster means. Therefore, the K-Means algorithm is usually repeated several times with different cluster assignments, and the best cluster assignment, defined as the one where the sum of squared distances of datapoints to their closest cluster center is the lowest (this metric is also known as inertia). \n","\n","Here, we let the K-Means algorithm run for a maximum of 500 iterations, and repeat with 10 inital random initializations of cluster centers. We try the K-Means algorithm with 2 to 8 clusters. We then plot the inertias for the K-Means algorithms with different numbers of clusters.\n","\n","Before applying the K-Means algorithm, we first one-hot encode the categorical features, and scale all the features so that they lie in the range $[0, 1]$. Doing this is important as the K-Means algorithm relies on notions of distance and hence is highly sensitive to the scale of the features."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:08:36.452376Z","iopub.status.busy":"2023-04-18T18:08:36.451947Z","iopub.status.idle":"2023-04-18T18:08:36.480331Z","shell.execute_reply":"2023-04-18T18:08:36.479021Z","shell.execute_reply.started":"2023-04-18T18:08:36.452337Z"},"trusted":true},"outputs":[],"source":["data_kmeans = pd.get_dummies(data, drop_first=True)\n","scaler = MinMaxScaler()\n","data_kmeans = scaler.fit_transform(data_kmeans)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:08:36.484206Z","iopub.status.busy":"2023-04-18T18:08:36.482952Z","iopub.status.idle":"2023-04-18T18:08:38.438508Z","shell.execute_reply":"2023-04-18T18:08:38.437074Z","shell.execute_reply.started":"2023-04-18T18:08:36.484148Z"},"trusted":true},"outputs":[],"source":["# One-hot encoding and scaling the features:\n","\n","data_kmeans = pd.get_dummies(data, drop_first=True)\n","scaler = MinMaxScaler()\n","data_kmeans = scaler.fit_transform(data_kmeans)\n","\n","# Running the K-Means algorithm for different numbers of clusters:\n","\n","n_clusters = list(range(2, 9))\n","inertias = []\n","\n","for n in n_clusters:\n","    kmeans = KMeans(n_clusters=n, init='random', n_init=10, max_iter=500, random_state=42)\n","    kmeans.fit(data_kmeans)\n","    inertia = kmeans.inertia_\n","    inertias.append(inertia)\n","\n","# Plotting the inertia:\n","\n","plt.figure(figsize=(7, 5))\n","plt.plot(n_clusters, inertias)\n","plt.axvline(3, linestyle='--', c='r')\n","plt.xlabel('Number of clusters')\n","plt.ylabel('Inertia')\n","plt.title('Inertias for K-Means with different numbers of clusters')\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{},"source":["We can choose the optimal number of clusters using the so-called elbow method, where we look for an 'elbow' in the inertia plot, i.e., a point after which the drop in inertia becomes abruptly becomes more gradual. Hence, by the elbow method, 3 clusters would be chosen."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:08:38.440642Z","iopub.status.busy":"2023-04-18T18:08:38.440183Z","iopub.status.idle":"2023-04-18T18:08:38.520596Z","shell.execute_reply":"2023-04-18T18:08:38.519381Z","shell.execute_reply.started":"2023-04-18T18:08:38.440589Z"},"trusted":true},"outputs":[],"source":["kmeans = KMeans(n_clusters=3, init='random', n_init=10, max_iter=500, random_state=42)\n","data['cluster_k-means'] = kmeans.fit_predict(data_kmeans)"]},{"cell_type":"markdown","metadata":{},"source":["#### K-Modes clustering"]},{"cell_type":"markdown","metadata":{},"source":["Since our data is mostly categorical, the K-Means algorithm, which calculates the Euclidean distance from the cluster centers to each datapoint, is likely to not produce a good clustering, since the Euclidean distance between cluster centers and categorical features, which have been one-hot encoded and therefore take either 0 or 1 as values, does not make much sense. The K-Modes algorithm is a modification of K-Means more suited for categorical data. Instead of calculating the Euclidean distance between the datapoints and cluster centers, in K-Modes, a dissimilarity measure is used, which is defined as the number of features of the datapoint whose values do not match those of the cluster center. Also, the cluster centers are updated using the mode of the datapoints assigned to each cluster, instead of the mean. \n","\n","Below, we turn age and balance into categorical variables by binning them, and one-hot encode all the categorical variables. We then implement the K-Modes algorithm for 2 to 8 clusters. We then produce plots of the cost for each number of clusters. The cost of the K-Modes algorithm is defined as the sum of the dissimilarities of each datapoint."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:08:38.522801Z","iopub.status.busy":"2023-04-18T18:08:38.522366Z","iopub.status.idle":"2023-04-18T18:15:24.727719Z","shell.execute_reply":"2023-04-18T18:15:24.726276Z","shell.execute_reply.started":"2023-04-18T18:08:38.522763Z"},"trusted":true},"outputs":[],"source":["# Binning the age columns and one-hot encoding:\n","\n","data_kmodes = data.drop('cluster_k-means', axis=1).copy()\n","data_kmodes['age_binned'] = pd.cut(data_kmodes['age'], bins=[10, 20, 30, 40, 50, 60, 70, 80, 90, 100]).astype('category')\n","data_kmodes.drop('age', axis=1, inplace=True)\n","data_kmodes['balance_binned'] = pd.cut(data_kmodes['balance'], bins=[2000, 5000, 10000, 20000, 50000, 100000]).astype('category')\n","data_kmodes.drop('balance', axis=1, inplace=True)\n","data_kmodes = pd.get_dummies(data_kmodes, drop_first=True)\n","\n","# Running the K-Modes algorithm for different numbers of clusters:\n","\n","n_clusters = list(range(2, 9))\n","costs = []\n","\n","for n in n_clusters:\n","    kmodes = KModes(n_clusters=n, init='random', n_init=10, max_iter=500, random_state=42)\n","    kmodes.fit(data_kmodes)\n","    cost = kmodes.cost_\n","    costs.append(cost)\n","\n","# Plotting the cost:\n","\n","plt.figure(figsize=(7,5))\n","plt.plot(n_clusters, costs)\n","plt.axvline(3, linestyle='--', c='r')\n","plt.xlabel('Number of clusters')\n","plt.ylabel('Cost')\n","plt.title('Costs for K-Modes with different numbers of clusters')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["The elbow method used on the cost curve suggests that the optimal number of clusters is 3. We choose 3 clusters for our final K-Modes model:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:15:24.729749Z","iopub.status.busy":"2023-04-18T18:15:24.72928Z","iopub.status.idle":"2023-04-18T18:16:07.59224Z","shell.execute_reply":"2023-04-18T18:16:07.590829Z","shell.execute_reply.started":"2023-04-18T18:15:24.729713Z"},"trusted":true},"outputs":[],"source":["kmodes = KModes(n_clusters=3, init='random', n_init=10, max_iter=500, random_state=42)\n","data['cluster_k-modes'] = kmodes.fit_predict(data_kmodes)"]},{"cell_type":"markdown","metadata":{},"source":["#### Hierarchical clustering"]},{"cell_type":"markdown","metadata":{},"source":["Hierarchical clustering is a bottom-up approach to clustering that does not require us to specify the number of clusters. It works by first treating each datapoint as its own cluster. The clusters that are most similar are then combined. This process is continued until all the observations are grouped into one cluster. To determine the most similar two clusters, a dissimilarity measure along with a method linkage have to be defined. The dissimilarity measure is usually defined as the Euclidean distance. An alternative is correlation based dissimilarity, which is one minus the correlation coefficient. The dissimilarity measure can be used to measure how 'dissimilar' two datapoints are. In order to extend this notion of dissimilarity to clusters, a method of linkage has to be defined. Generally, three methods of linkage are used -- complete, single and average. In all of these methods of linkage, first, the dissimilarity measures between all the datapoints in two clusters are computed. Then, in complete linkage, the maximum value of these dissimilarities between datapoints is used to determine the dissimilarity between the two clusters. In single linkage, the minimum value of the dissimilarities between the datapoints is used, and in average linkage, the mean value is used.\n","\n","Hierarchical clustering can be used to prodce a dendrogram, which is a tree-like diagram that has all the datapoints as individual clusters at the bottom. As we move up the dendrogram, clusters are formed, one by one, until we end up with a single cluster containing all the datapoints at the top.\n","\n","Below, we perform hierarchical clustering and plot the dendrograms using the three types of linkage previously mentioned. Euclidean distance is taken as the dissimilarity measure. As the hierarchical clustering algorithm, like the K-Means algorithm, relies on notions of Euclidean distance, the data for the hierarchical clustering model is preprocessed in the same way as for the K-Means algorithm."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:16:07.594615Z","iopub.status.busy":"2023-04-18T18:16:07.593896Z","iopub.status.idle":"2023-04-18T18:27:05.514171Z","shell.execute_reply":"2023-04-18T18:27:05.512784Z","shell.execute_reply.started":"2023-04-18T18:16:07.594562Z"},"trusted":true},"outputs":[],"source":["data_hc = data_kmeans.copy()\n","\n","plt.figure(figsize=(14, 6))\n","hc_complete = linkage(data_hc, method='complete')\n","dendrogram_complete = dendrogram(hc_complete)\n","plt.title('Dendrogram - complete linkage')\n","plt.xlabel('Bank clients')\n","plt.ylabel('Euclidean distances')\n","plt.show()\n","\n","plt.figure(figsize=(14, 6))\n","hc_average = linkage(data_hc, method='average')\n","dendrogram_average = dendrogram(hc_average)\n","plt.title('Dendrogram - average linkage')\n","plt.xlabel('Bank clients')\n","plt.ylabel('Euclidean distances')\n","plt.show()\n","\n","plt.figure(figsize=(14, 6))\n","hc_single = linkage(data_hc, method='single')\n","dendrogram_single = dendrogram(hc_single)\n","plt.title('Dendrogram - single linkage')\n","plt.xlabel('Bank clients')\n","plt.ylabel('Euclidean distances')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["It looks like using hierarchical clustering with complete linkage produces the most balanced clusters. We therefore continue our analysis using hierarchical clustering with complete linkage. We use 3 clusters:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:27:05.515917Z","iopub.status.busy":"2023-04-18T18:27:05.515545Z","iopub.status.idle":"2023-04-18T18:27:07.214943Z","shell.execute_reply":"2023-04-18T18:27:07.213645Z","shell.execute_reply.started":"2023-04-18T18:27:05.515881Z"},"trusted":true},"outputs":[],"source":["data['cluster_hc'] = cut_tree(hc_complete, 3)[:, 0]"]},{"cell_type":"markdown","metadata":{},"source":["# Dimensionality reduction using PCA and evaluation of the considered clustering algorithms"]},{"cell_type":"markdown","metadata":{},"source":["We now use principal component analysis (PCA) to obtain a 2-dimensional representation of the features. PCA is an unsupervised learning algorithm that expresses the features of a dataset as principal components, which are linear combinations of the features such that all the principal components are uncorrelated with each other, and successive principal components have diminishing variance. PCA is a useful technique to decorrelate highly correlated features, to reduce the dimensionality of datasets with very large numbers of features, or to reduce the dimensionality in order to visualize the features in two or three dimensional space. \n","\n","Here, we use PCA to find the first two principal components, which can then be plotted using a scatterplot. We then color these scatterplots by cluster for each of the clustering algorithms considered, and inspect them visually to determine the optimal clustering algorithm for our problem.\n","\n","An important assumption of PCA is that all the features have the same means and standard deviations. Therefore, we first one-hot encode the original dataset containing the features, and then scale it so that each feature has zero mean and unit standard deviation, before performing PCA and printing the proportion of variance of the original features explained by the first two principal components:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:27:07.217291Z","iopub.status.busy":"2023-04-18T18:27:07.21632Z","iopub.status.idle":"2023-04-18T18:27:07.310611Z","shell.execute_reply":"2023-04-18T18:27:07.309231Z","shell.execute_reply.started":"2023-04-18T18:27:07.217249Z"},"trusted":true},"outputs":[],"source":["# Scaling the original features:\n","\n","features = data.iloc[:, :8]\n","features = pd.get_dummies(features, drop_first=True)\n","scaler = StandardScaler()\n","features = scaler.fit_transform(features)\n","\n","# Getting the first two principal components:\n","\n","pca = PCA(2)\n","data_pca = pd.DataFrame(pca.fit_transform(features), columns=['Principal component 1', 'Principal component 2'])\n","\n","# Printing the explained variance ratio:\n","\n","explained_variance_ratio = np.sum(pca.explained_variance_ratio_)\n","print(f'Proportion of variance of the original features explained by the first two principal components: {explained_variance_ratio}')\n","\n","# Appending the cluster labels to the PCA dataframe:\n","\n","data_pca = pd.concat([data_pca, data.iloc[:, 8:11]], axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["The first two principal components explain only around 23% of the variance of the original features. Nevertheless, we use them to plot a scatterplot and visualize the clusters formed by the different clustering algorithms:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:27:07.313014Z","iopub.status.busy":"2023-04-18T18:27:07.312245Z","iopub.status.idle":"2023-04-18T18:27:09.09607Z","shell.execute_reply":"2023-04-18T18:27:09.094636Z","shell.execute_reply.started":"2023-04-18T18:27:07.312961Z"},"trusted":true},"outputs":[],"source":["fig, axs = plt.subplots(ncols=3, figsize=(20, 5))\n","sns.scatterplot(data=data_pca, x='Principal component 1', y='Principal component 2', hue='cluster_k-means', ax=axs[0], palette='Set1')\n","axs[0].set_title('Clusters: K-Means')\n","sns.scatterplot(data=data_pca, x='Principal component 1', y='Principal component 2', hue='cluster_k-modes', ax=axs[1], palette='Set1')\n","axs[1].set_title('Clusters: K-Modes')\n","sns.scatterplot(data=data_pca, x='Principal component 1', y='Principal component 2', hue='cluster_hc', ax=axs[2], palette='Set1')\n","axs[2].set_title('Clusters: Hierarchical clustering')\n","fig.suptitle('Scatterplots of the first two principal components')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["None of the algorithms considered produced well-seperated clusters on the first two principal components. It must be noted, however, that analysis based on the first two principal components in this case may not be appropriate because of two reasons. Firstly, as previously explained, the first two principal components explain only a small proportion of the total variance of the original features. Secondly, PCA is usually applied to numeric data, while we have mostly categorical features. Alternative dimensionality reduction methods, such as FAMD (factorical analysis of mixed data) may be used to get a more accurate lower dimensional representation of the data.\n","\n","Since analysis based on the first two principal components does not yield any conclusive results about the relative performance of the clustering algorithms chosen, we choose the clustering algorithm that is best suited for (mostly) categorical data, i.e., the K-Modes algorithm, and use it for further analysis of our data."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:27:09.098698Z","iopub.status.busy":"2023-04-18T18:27:09.097578Z","iopub.status.idle":"2023-04-18T18:27:09.107974Z","shell.execute_reply":"2023-04-18T18:27:09.106494Z","shell.execute_reply.started":"2023-04-18T18:27:09.098645Z"},"trusted":true},"outputs":[],"source":["data.drop(['cluster_k-means', 'cluster_hc'], axis=1, inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Exploring the data by cluster"]},{"cell_type":"markdown","metadata":{},"source":["Plotting frequency plots for the variable 'job', by cluster:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:27:09.109828Z","iopub.status.busy":"2023-04-18T18:27:09.109461Z","iopub.status.idle":"2023-04-18T18:27:10.132423Z","shell.execute_reply":"2023-04-18T18:27:10.131091Z","shell.execute_reply.started":"2023-04-18T18:27:09.109793Z"},"trusted":true},"outputs":[],"source":["g = sns.displot(data=data, x='job', col='cluster_k-modes', multiple=\"dodge\", stat='density', shrink=0.8, common_norm=False)\n","g.set_xticklabels(rotation=90)\n","g.fig.suptitle(\"Frequency plots for the variable 'job', by cluster\", y=1.05)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["We see that in clusters 0, most of the clients are blue-collar workers, followed by technicians. In cluster 1, most of the clients are technicians, with administrative and blue-collar jobs running second. In cluster 2, the overwhelming majority of clients are employed in management roles."]},{"cell_type":"markdown","metadata":{},"source":["Plotting frequency plots for the variable 'marital', by cluster:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:27:10.134852Z","iopub.status.busy":"2023-04-18T18:27:10.133958Z","iopub.status.idle":"2023-04-18T18:27:10.762369Z","shell.execute_reply":"2023-04-18T18:27:10.7611Z","shell.execute_reply.started":"2023-04-18T18:27:10.134807Z"},"trusted":true},"outputs":[],"source":["g = sns.displot(data=data, x='marital', col='cluster_k-modes', multiple=\"dodge\", stat='density', shrink=0.8, common_norm=False)\n","g.fig.suptitle(\"Frequency plots for the variable 'marital', by cluster\", y=1.05)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["In clsuter 0, most of the clients are married and a small proportion is divorced. In cluster 1, most of the clients are single and a small proportion is divorced. In cluster 2, most of the clients are married, some are single and a small proportion is divorced."]},{"cell_type":"markdown","metadata":{},"source":["Plotting frequency plots for the variable 'education', by cluster:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:27:10.7643Z","iopub.status.busy":"2023-04-18T18:27:10.763943Z","iopub.status.idle":"2023-04-18T18:27:11.430806Z","shell.execute_reply":"2023-04-18T18:27:11.429463Z","shell.execute_reply.started":"2023-04-18T18:27:10.764265Z"},"trusted":true},"outputs":[],"source":["g = sns.displot(data=data, x='education', col='cluster_k-modes', multiple=\"dodge\", stat='density', shrink=0.8, common_norm=False)\n","g.set_xticklabels(rotation=90)\n","g.fig.suptitle(\"Frequency plots for the variable 'education', by cluster\", y=1.05)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["In clusters 0 and 1, most of the clients have education upto the secondary level. In cluster 0, primary education is the second most common level of education, while in cluster 1, tertiary education is the second most common level of education. In cluster 2, almost all the clients have a tertiary level of education."]},{"cell_type":"markdown","metadata":{},"source":["Plotting frequency plots for the variable 'default', by cluster:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:27:11.432596Z","iopub.status.busy":"2023-04-18T18:27:11.432242Z","iopub.status.idle":"2023-04-18T18:27:12.026094Z","shell.execute_reply":"2023-04-18T18:27:12.024788Z","shell.execute_reply.started":"2023-04-18T18:27:11.43256Z"},"trusted":true},"outputs":[],"source":["g = sns.displot(data=data, x='default', col='cluster_k-modes', multiple=\"dodge\", stat='density', shrink=0.8, common_norm=False)\n","g.fig.suptitle(\"Frequency plots for the variable 'default', by cluster\", y=1.05)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["There are no significant differences across the different clusters in terms of whether the clients have credit in default -- in all three clusters, most clients do not have credit in default."]},{"cell_type":"markdown","metadata":{},"source":["Plotting frequency plots for the variable 'housing', by cluster:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:27:12.032315Z","iopub.status.busy":"2023-04-18T18:27:12.031932Z","iopub.status.idle":"2023-04-18T18:27:12.658146Z","shell.execute_reply":"2023-04-18T18:27:12.656895Z","shell.execute_reply.started":"2023-04-18T18:27:12.032281Z"},"trusted":true},"outputs":[],"source":["g = sns.displot(data=data, x='housing', col='cluster_k-modes', multiple=\"dodge\", stat='density', shrink=0.8, common_norm=False)\n","g.fig.suptitle(\"Frequency plots for the variable 'housing', by cluster\", y=1.05)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["In cluster 0, most of the clients have housing loans, while in clusters 1 and 2, most of them do not."]},{"cell_type":"markdown","metadata":{},"source":["Plotting frequency plots for the variable 'loan', by cluster:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:27:12.660724Z","iopub.status.busy":"2023-04-18T18:27:12.659943Z","iopub.status.idle":"2023-04-18T18:27:13.925717Z","shell.execute_reply":"2023-04-18T18:27:13.924363Z","shell.execute_reply.started":"2023-04-18T18:27:12.660671Z"},"trusted":true},"outputs":[],"source":["g = sns.displot(data=data, x='loan', col='cluster_k-modes', multiple=\"dodge\", stat='density', shrink=0.8, common_norm=False)\n","g.fig.suptitle(\"Frequency plots for the variable 'loan', by cluster\", y=1.05)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Again, there are no significant differences across the different clusters in terms of whether the clients have housing loans -- in all three clusters, most of the clients have no personal loans."]},{"cell_type":"markdown","metadata":{},"source":["Plotting histograms for the variable 'age', by cluster:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:27:13.930834Z","iopub.status.busy":"2023-04-18T18:27:13.927467Z","iopub.status.idle":"2023-04-18T18:27:14.912494Z","shell.execute_reply":"2023-04-18T18:27:14.910924Z","shell.execute_reply.started":"2023-04-18T18:27:13.930788Z"},"trusted":true},"outputs":[],"source":["g = sns.displot(data=data, x='age', col='cluster_k-modes', bins=[10, 20, 30, 40, 50, 60, 70, 80, 90])\n","g.fig.suptitle(\"Histograms for the variable 'age', by cluster\", y=1.05)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["In all three clusters, most of the clients are between 30 and 40 years of age. There is a larger proportion of poeple younger than 30 in cluster 1 compared to clusters 0 and 2."]},{"cell_type":"markdown","metadata":{},"source":["Plotting histograms for the variable 'balance', by cluster:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-18T18:27:14.914329Z","iopub.status.busy":"2023-04-18T18:27:14.913977Z","iopub.status.idle":"2023-04-18T18:27:15.838115Z","shell.execute_reply":"2023-04-18T18:27:15.836661Z","shell.execute_reply.started":"2023-04-18T18:27:14.914296Z"},"trusted":true},"outputs":[],"source":["g = sns.displot(data=data, x='balance', col='cluster_k-modes', bins=[2000, 5000, 10000, 20000, 50000, 100000])\n","g.fig.suptitle(\"Histograms for the variable 'age', by cluster\", y=1.05)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["The distribution of bank balances is very similar across the clusters."]},{"cell_type":"markdown","metadata":{},"source":["# Conclusion"]},{"cell_type":"markdown","metadata":{},"source":["Summarizing the differences between the clusters:\n","1. In cluster 0, most clients are blue-collar workers or technicians, are married, are educated upto the primary or secondary levels, have housing loans, and are between 30 and 60 years of age.\n","2. In cluster 1, most clients are technicians, blue-collar workers or work administrative jobs, are single, are educated upto the secondary or tertiary levels, do not have housing loans, and are between 20 and 40 years of age.\n","3. In cluster 2, most clients work management jobs, are married, are educated upto the tertiary level, do not have housing loans, and are between 30 and 60 years of age.\n","\n","It may be concluded that most of the clients in cluster 2 have the highest income, based on their jobs, education, and age. Clients in clusters 0 and 1 have lower incomes, but for different reasons -- the clients in cluster 1 are in general more educated, are employed in higher paying occupations, but are younger and hence have less working experience compared to the clients in cluster 0. It may also be concluded that based on the differences in education and employment between the clusters, most of the clients in clusters 1 and 2 have a greater degree of financial literacy than those in cluster 0. \n","\n","Subsequently, it is likely that the highest proportion of clients that are certain about their need to have a term deposit and have a term deposit (or vice-versa) lie in cluster 2, followed by cluster 1 and then cluster 0. Based on the results of our clustering analysis, the bank should focus more on targeting clients in clusters 0 and 1. This could make the marketing campaign more effective as well as reduce costs of the marketing campaign."]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4471,"sourceId":6849,"sourceType":"datasetVersion"}],"dockerImageVersionId":30458,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":4}
